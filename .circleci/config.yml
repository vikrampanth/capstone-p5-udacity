version: 2.1

defaultpythonimage: &defaultpythonimage
  docker:
    - image: python:3.7-alpine3.11

orbs:
  aws-eks: circleci/aws-eks@1.1.0
  kubernetes: circleci/kubernetes@0.12.0
  aws-cli: circleci/aws-cli@1.3.0

commands:
  aws-cli-setup-python:
    description: Install AWS CLI
    steps:
      - run:
          name: Install AWS command
          command: |
            apk add --no-cache python3 py3-pip \
            && pip3 install --upgrade pip \
            && pip3 install awscli
  
  destroy-environment:
    description: Destroy EKS Cluster
    steps:
      - run:
          name: Destroy ESK Cluster
          when: on_fail
          command: |
            make ekstl-install
            eksctl delete cluster --name="Capstone-${CIRCLE_WORKFLOW_ID:0:7}"

jobs:

  lint:
    <<: *defaultpythonimage
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk update
            apk add --update make
      - run:
          name: "Linting"
          command: |
            make hadolint-install
            make lint

  build-upload-image:
    <<: *defaultpythonimage
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk update && apk add bash
      - setup_remote_docker:
          version: 19.03.13      
      - run:
          name: Install Docker client
          command: apk add docker-cli
      - run:
          name: Build Docker Image
          command: |
            chmod +x run_docker.sh
            ./run_docker.sh
      - run:
          name: Upload to docker Hub
          command: |
            chmod +x upload_docker.sh
            ./upload_docker.sh

  create-kubernetes-cluster:
    docker:
      - image: alpine/k8s:1.15.12
    working_directory: /tmp/workspace
    steps:
      - checkout
      - run:
          name: Store old cluster name
          command: |
            echo $(aws eks list-clusters --query 'clusters[0]' --output text) > cluster.txt
            cat cluster.txt
      - run:
          name: create kubernetes cluster
          command: |
            eksctl create cluster --name="Capstone-${CIRCLE_WORKFLOW_ID:0:7}" \
            --nodes-min=4 --nodes-max=6 \
            --node-type=t3.medium
      - persist_to_workspace:
          root: /tmp/workspace
          paths:
            - cluster.txt

  deploy:
    <<: *defaultpythonimage
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk update && apk add bash
            apk add --update curl
            apk add --update make
      - aws-cli-setup-python
      - kubernetes/install
      - run:
          name: Deploy Container to EKS
          command: |
            aws eks --region us-west-2 update-kubeconfig --name "Capstone-${CIRCLE_WORKFLOW_ID:0:7}"
            kubectl config use-context arn:aws:eks:us-west-2:877716312368:cluster/Capstone-${CIRCLE_WORKFLOW_ID:0:7}
            kubectl apply -f kubernetes/aws-auth-cm.yaml
            kubectl apply -f kubernetes/deployment.yml
            kubectl apply -f kubernetes/service.yml
            kubectl get nodes
            echo "--------------------deployment---------------------------"
            kubectl get deployment
            kubectl describe deployment
            echo "---------------------------pods---------------------------"
            kubectl get pod -o wide
            kubectl describe pods
            echo "---------------------------service---------------------------"
            kubectl get service
            kubectl describe service
      - destroy-environment

  smoke-test:
    <<: *defaultpythonimage
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk update && apk add bash
            apk add --update curl
            apk add --update make
     - aws-cli-setup-python
      - kubernetes/install
      - run:
          name: Smoke test
          command: |
            aws eks --region us-west-2 update-kubeconfig --name "Capstone-${CIRCLE_WORKFLOW_ID:0:7}"
            kubectl config use-context arn:aws:eks:us-west-2:877716312368:cluster/Capstone-${CIRCLE_WORKFLOW_ID:0:7}
            kubectl apply -f kubernetes/aws-auth-cm.yaml
            echo "$(kubectl get services capstone-service --output jsonpath='{.status.loadBalancer.ingress[0].hostname}')" > capstone-service.txt
            FRONTEND_IP=$(tr -d '\n' < capstone-service.txt)
            frontend_url="http://${FRONTEND_IP}:8080"
            echo $frontend_url
            if curl --silent --head $frontend_url 
            then
              echo "URL exists: $frontend_url"
            else
              echo "URL does not exist: $frontend_url"
            fi         
      - destroy-environment

  cleanup:
    <<: *defaultpythonimage
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            apk update && apk add bash
            apk add --update curl
            apk add --update make
      - aws-cli-setup-python
      - kubernetes/install
      - attach_workspace:
          at: /tmp/workspace
      - run:
          name: delete old clusters
          command: |
            make ekstl-install
            aws eks update-kubeconfig --name "Capstone-${CIRCLE_WORKFLOW_ID:0:7}"
            cluster_name=$(tr -d '\n' < cluster.txt)
            echo $cluster_name
            if [ "$cluster_name" = "null" ]
            then
              echo $cluster_name 
            else
              eksctl delete cluster --name=$cluster_name
            fi

workflows:
  default:
    jobs:
      - lint
      - build-upload-image:
          requires: [lint]
      - create-kubernetes-cluster:
          requires: [build-upload-image]
          filters:
            branches:
              only: [main]          
      - deploy:
          requires: [create-kubernetes-cluster]
      - smoke-test:
          requires: [deploy]
      - cleanup:
          requires: [smoke-test]
